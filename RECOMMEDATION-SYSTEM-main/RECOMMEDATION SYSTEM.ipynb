{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a384ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies_df = pd.read_csv('movies.csv')\n",
    "ratings_df = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ac8a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of movies dataframe are: (9742, 3) \n",
      "The dimensions of ratings dataframe are: (100836, 4)\n"
     ]
    }
   ],
   "source": [
    "print('The dimensions of movies dataframe are:', movies_df.shape,'\\nThe dimensions of ratings dataframe are:', ratings_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e93a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f038ef0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at ratings_df\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c93d15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 610\n",
      "Number of unique movies: 9724\n",
      "The full rating matrix will have: 5931640 elements.\n",
      "----------\n",
      "Number of ratings: 100836\n",
      "Therefore:  1.6999683055613624 % of the matrix is filled.\n",
      "We have an incredibly sparse matrix to work with here.\n",
      "And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n",
      "You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n",
      "One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"
     ]
    }
   ],
   "source": [
    "movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
    "n_users = len(ratings_df.userId.unique())\n",
    "n_items = len(ratings_df.movieId.unique())\n",
    "print(\"Number of unique users:\", n_users)\n",
    "print(\"Number of unique movies:\", n_items)\n",
    "print(\"The full rating matrix will have:\", n_users*n_items, 'elements.')\n",
    "print('----------')\n",
    "print(\"Number of ratings:\", len(ratings_df))\n",
    "print(\"Therefore: \", len(ratings_df) / (n_users*n_items) * 100, '% of the matrix is filled.')\n",
    "print(\"We have an incredibly sparse matrix to work with here.\")\n",
    "print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n",
    "print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n",
    "print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959c585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = ratings_df.copy()\n",
    "        users = ratings_df.userId.unique()\n",
    "        movies = ratings_df.movieId.unique()\n",
    "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
    "        \n",
    "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
    "       \n",
    "        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n",
    "        \n",
    "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
    "        self.y = self.ratings['rating'].values\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3376714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: False\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(1000, 8, sparse=True)\n",
      "  (item_factors): Embedding(1000, 8, sparse=True)\n",
      ")\n",
      "user_factors.weight tensor([[-1.4160, -1.1159, -0.1101,  ..., -0.5719,  0.5045, -0.2853],\n",
      "        [ 0.2546, -0.2217, -0.0050,  ..., -0.4236,  1.6753, -0.4730],\n",
      "        [ 1.1924, -0.2979,  0.9626,  ...,  1.3267,  0.3650, -1.0674],\n",
      "        ...,\n",
      "        [-1.8009, -0.0312, -1.5954,  ..., -0.4758,  0.3751, -1.2936],\n",
      "        [ 1.2020,  0.0313,  0.2394,  ..., -0.2082,  0.1170, -0.3914],\n",
      "        [-3.4803, -0.3363,  0.3832,  ..., -0.7835, -0.8711,  0.0221]])\n",
      "item_factors.weight tensor([[ 0.5070,  0.3652, -1.5157,  ...,  0.3250, -1.7843, -0.6380],\n",
      "        [ 0.5755,  1.1181, -0.4449,  ...,  1.3206, -1.2557,  1.0866],\n",
      "        [-0.5849, -0.5160,  1.5197,  ...,  0.4648,  1.0287,  0.0358],\n",
      "        ...,\n",
      "        [-1.7064, -0.4485,  0.3200,  ...,  1.3188, -0.9324,  1.8111],\n",
      "        [-0.7862, -1.2211,  0.6928,  ..., -0.1242,  0.8121,  0.1035],\n",
      "        [ 0.7346,  0.1527, -0.4019,  ..., -0.6419, -0.4850, -0.9334]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m---> 46\u001b[0m     users, items, ratings \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cuda:\n\u001b[0;32m     48\u001b[0m         users \u001b[38;5;241m=\u001b[39m users\u001b[38;5;241m.\u001b[39mcuda()\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the MatrixFactorization model\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=8):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors, sparse=True)\n",
    "        self.item_factors = nn.Embedding(n_items, n_factors, sparse=True)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_factors = self.user_factors(user)\n",
    "        item_factors = self.item_factors(item)\n",
    "        return (user_factors * item_factors).sum(1)\n",
    "\n",
    "# Assuming n_users and n_items are defined elsewhere in your code\n",
    "n_users = 1000  # Example number of users, replace with actual number\n",
    "n_items = 1000  # Example number of items, replace with actual number\n",
    "\n",
    "num_epochs = 128\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        users, items, ratings = batch\n",
    "        if cuda:\n",
    "            users = users.cuda()\n",
    "            items = items.cuda()\n",
    "            ratings = ratings.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(users, items)\n",
    "        loss = loss_fn(outputs, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f513e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MatrixFactorization.forward() missing 1 required positional argument: 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcuda(), y\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs\u001b[38;5;241m.\u001b[39msqueeze(), y\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m     11\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: MatrixFactorization.forward() missing 1 required positional argument: 'item'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for it in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ed2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[ 0.6566,  1.5865,  1.4255,  ...,  1.6873,  0.7072,  1.8206],\n",
      "        [ 2.3735,  0.6803,  1.4607,  ...,  1.3688,  0.4064,  1.0991],\n",
      "        [ 1.9848,  0.8896, -3.5604,  ...,  0.9796, -0.3901, -0.2799],\n",
      "        ...,\n",
      "        [ 0.0275,  1.6872,  1.4219,  ...,  1.6841,  1.5586, -1.1896],\n",
      "        [ 1.0926,  0.8030,  1.4236,  ...,  1.0499,  1.4311,  0.8676],\n",
      "        [ 1.8563,  0.9356,  0.3273,  ...,  1.0134,  1.6467,  1.3681]])\n",
      "item_factors.weight tensor([[ 0.6710,  0.1434,  0.5828,  ...,  0.1939,  0.5384,  0.6981],\n",
      "        [ 0.4802,  0.4188,  0.6303,  ...,  0.3990, -0.0062,  0.5881],\n",
      "        [ 0.3190,  0.4571,  0.5744,  ...,  0.5104,  0.7044,  0.0860],\n",
      "        ...,\n",
      "        [ 0.3506,  0.3344,  0.3727,  ...,  0.3402,  0.3474,  0.3565],\n",
      "        [ 0.4232,  0.4131,  0.4125,  ...,  0.4102,  0.4085,  0.4064],\n",
      "        [ 0.4045,  0.4208,  0.4298,  ...,  0.4318,  0.3967,  0.4107]])\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "uw = 0\n",
    "iw = 0 \n",
    "for name, yash in model.named_parameters():\n",
    "    if yash.requires_grad:\n",
    "        print(name, yash.data)\n",
    "        if c == 0:\n",
    "          uw = yash.data\n",
    "          c +=1\n",
    "        else:\n",
    "          iw = yash.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd99b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f69abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trained_movie_embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c83f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "\t Forrest Gump (1994)\n",
      "\t Shawshank Redemption, The (1994)\n",
      "\t Silence of the Lambs, The (1991)\n",
      "\t Matrix, The (1999)\n",
      "\t Star Wars: Episode IV - A New Hope (1977)\n",
      "\t Fight Club (1999)\n",
      "\t Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "\t Usual Suspects, The (1995)\n",
      "\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "\t Fugitive, The (1993)\n",
      "Cluster #1\n",
      "\t Pulp Fiction (1994)\n",
      "\t American Beauty (1999)\n",
      "\t Seven (a.k.a. Se7en) (1995)\n",
      "\t Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
      "\t Godfather, The (1972)\n",
      "\t Ace Ventura: Pet Detective (1994)\n",
      "\t Memento (2000)\n",
      "\t Monty Python and the Holy Grail (1975)\n",
      "\t Reservoir Dogs (1992)\n",
      "\t Kill Bill: Vol. 1 (2003)\n",
      "Cluster #2\n",
      "\t Dances with Wolves (1990)\n",
      "\t Stargate (1994)\n",
      "\t Home Alone (1990)\n",
      "\t Waterworld (1995)\n",
      "\t Net, The (1995)\n",
      "\t Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "\t Back to the Future Part III (1990)\n",
      "\t Unbreakable (2000)\n",
      "\t Pirates of the Caribbean: Dead Man's Chest (2006)\n",
      "\t Tombstone (1993)\n",
      "Cluster #3\n",
      "\t Coneheads (1993)\n",
      "\t Anaconda (1997)\n",
      "\t Super Mario Bros. (1993)\n",
      "\t Barb Wire (1996)\n",
      "\t Speed 2: Cruise Control (1997)\n",
      "\t Mighty Morphin Power Rangers: The Movie (1995)\n",
      "\t Superman IV: The Quest for Peace (1987)\n",
      "\t Nutty Professor II: The Klumps (2000)\n",
      "\t Next Karate Kid, The (1994)\n",
      "\t Volcano (1997)\n",
      "Cluster #4\n",
      "\t Star Wars: Episode I - The Phantom Menace (1999)\n",
      "\t Titanic (1997)\n",
      "\t Batman Forever (1995)\n",
      "\t Pretty Woman (1990)\n",
      "\t Twister (1996)\n",
      "\t Star Trek: Generations (1994)\n",
      "\t Sleepless in Seattle (1993)\n",
      "\t Crimson Tide (1995)\n",
      "\t Cliffhanger (1993)\n",
      "\t Firm, The (1993)\n",
      "Cluster #5\n",
      "\t Independence Day (a.k.a. ID4) (1996)\n",
      "\t Mask, The (1994)\n",
      "\t Dumb & Dumber (Dumb and Dumber) (1994)\n",
      "\t Terminator, The (1984)\n",
      "\t Rock, The (1996)\n",
      "\t American Pie (1999)\n",
      "\t Outbreak (1995)\n",
      "\t Happy Gilmore (1996)\n",
      "\t Matrix Reloaded, The (2003)\n",
      "\t Armageddon (1998)\n",
      "Cluster #6\n",
      "\t Aladdin (1992)\n",
      "\t Shrek (2001)\n",
      "\t Beauty and the Beast (1991)\n",
      "\t Princess Bride, The (1987)\n",
      "\t Finding Nemo (2003)\n",
      "\t Ghost (1990)\n",
      "\t Breakfast Club, The (1985)\n",
      "\t Up (2009)\n",
      "\t Harry Potter and the Chamber of Secrets (2002)\n",
      "\t Harry Potter and the Prisoner of Azkaban (2004)\n",
      "Cluster #7\n",
      "\t Jurassic Park (1993)\n",
      "\t Toy Story (1995)\n",
      "\t Apollo 13 (1995)\n",
      "\t Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "\t Batman (1989)\n",
      "\t True Lies (1994)\n",
      "\t Back to the Future (1985)\n",
      "\t Speed (1994)\n",
      "\t Gladiator (2000)\n",
      "\t Men in Black (a.k.a. MIB) (1997)\n",
      "Cluster #8\n",
      "\t Braveheart (1995)\n",
      "\t Terminator 2: Judgment Day (1991)\n",
      "\t Schindler's List (1993)\n",
      "\t Saving Private Ryan (1998)\n",
      "\t Fargo (1996)\n",
      "\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "\t Alien (1979)\n",
      "\t One Flew Over the Cuckoo's Nest (1975)\n",
      "\t Godfather: Part II, The (1974)\n",
      "\t Goodfellas (1990)\n",
      "Cluster #9\n",
      "\t Sense and Sensibility (1995)\n",
      "\t Blair Witch Project, The (1999)\n",
      "\t Signs (2002)\n",
      "\t Sabrina (1995)\n",
      "\t Godfather: Part III, The (1990)\n",
      "\t Inside Out (2015)\n",
      "\t Don Juan DeMarco (1995)\n",
      "\t Nell (1994)\n",
      "\t Bowfinger (1999)\n",
      "\t Panic Room (2002)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "for cluster in range(10):\n",
    "    print(\"Cluster #{}\".format(cluster))\n",
    "    movs = []\n",
    "    for movidx in np.nonzero(kmeans.labels_ == cluster)[0]:\n",
    "        movid = train_set.idx2movieid[movidx]\n",
    "        rat_count = ratings_df.loc[ratings_df['movieId']==movid].iloc[:, 0].count()\n",
    "        movs.append((movie_names[movid], rat_count))\n",
    "    for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "        print(\"\\t\", mov[0])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b9a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
